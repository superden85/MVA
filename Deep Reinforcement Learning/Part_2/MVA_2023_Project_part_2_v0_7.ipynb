{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0726DI1W8RJ"
      },
      "source": [
        "# Project part 2: beat flappy bird\n",
        "\n",
        "You may be familiar with the game [flappy bird](https://flappybird.io/). It is very simple: a bird moves at constant speed on the x axis and, to direct him, you can either push it up or let it fall at each step. The goal of the game is to go as far as possible.\n",
        "\n",
        "Your goal for this project is as follow: design and train an agent which does the best possible score at flappy bird !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yiSc6BlkByJV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbc9d774-e79d-493d-ce7e-7390dfdc49d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# github.com:22 SSH-2.0-babeld-68a4aa58\n",
            "Cloning into 'rl_games'...\n",
            "Warning: Permanently added the ED25519 host key for IP address '140.82.114.4' to the list of known hosts.\n",
            "remote: Enumerating objects: 379, done.\u001b[K\n",
            "remote: Counting objects: 100% (265/265), done.\u001b[K\n",
            "remote: Compressing objects: 100% (173/173), done.\u001b[K\n",
            "remote: Total 379 (delta 141), reused 189 (delta 89), pack-reused 114\u001b[K\n",
            "Receiving objects: 100% (379/379), 2.84 MiB | 6.98 MiB/s, done.\n",
            "Resolving deltas: 100% (154/154), done.\n",
            "Warning: Permanently added the ED25519 host key for IP address '140.82.114.3' to the list of known hosts.\n",
            "Already up to date.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/rl_games\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: deep-rl\n",
            "  Building wheel for deep-rl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deep-rl: filename=deep_rl-1.0-py3-none-any.whl size=9674 sha256=885e7f4b9d0ecb128a881a9f242e8ef7bc56ff92a2e0b62c4d2d34b66ba921cf\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qiaacfup/wheels/c2/e8/71/abad0ca67ca613c707d70aebbed8049f314f8fc31ab31ae46f\n",
            "Successfully built deep-rl\n",
            "Installing collected packages: deep-rl\n",
            "Successfully installed deep-rl-1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dm-acme[jax]\n",
            "  Downloading dm-acme-0.4.0.tar.gz (314 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.1/314.1 KB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from dm-acme[jax]) (1.4.0)\n",
            "Collecting dm-env\n",
            "  Downloading dm_env-1.6-py3-none-any.whl (26 kB)\n",
            "Collecting dm-launchpad==0.5.0\n",
            "  Downloading dm_launchpad-0.5.0-cp39-cp39-manylinux2010_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dm-tree in /usr/local/lib/python3.9/dist-packages (from dm-acme[jax]) (0.1.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from dm-acme[jax]) (1.22.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from dm-acme[jax]) (8.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from dm-acme[jax]) (4.5.0)\n",
            "Requirement already satisfied: chex in /usr/local/lib/python3.9/dist-packages (from dm-acme[jax]) (0.1.7)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.9/dist-packages (from dm-acme[jax]) (0.4.7)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.9/dist-packages (from dm-acme[jax]) (0.4.7+cuda11.cudnn86)\n",
            "Collecting dm-haiku\n",
            "  Downloading dm_haiku-0.0.9-py3-none-any.whl (352 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 KB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flax in /usr/local/lib/python3.9/dist-packages (from dm-acme[jax]) (0.6.8)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.9/dist-packages (from dm-acme[jax]) (0.1.4)\n",
            "Collecting rlax\n",
            "  Downloading rlax-0.1.5-py3-none-any.whl (131 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.7/131.7 KB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dm-reverb==0.7.0\n",
            "  Downloading dm_reverb-0.7.0-cp39-cp39-manylinux2010_x86_64.whl (6.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras==2.8.0\n",
            "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-datasets==4.4.0\n",
            "  Downloading tensorflow_datasets-4.4.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator==2.8.0\n",
            "  Downloading tensorflow_estimator-2.8.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.3/462.3 KB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow==2.8.0\n",
            "  Downloading tensorflow-2.8.0-cp39-cp39-manylinux2010_x86_64.whl (497.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.6/497.6 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow_probability==0.15.0\n",
            "  Downloading tensorflow_probability-0.15.0-py2.py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.9/dist-packages (from dm-launchpad==0.5.0->dm-acme[jax]) (3.20.3)\n",
            "Requirement already satisfied: portpicker in /usr/local/lib/python3.9/dist-packages (from dm-launchpad==0.5.0->dm-acme[jax]) (1.3.9)\n",
            "Collecting mock\n",
            "  Downloading mock-5.0.1-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from dm-launchpad==0.5.0->dm-acme[jax]) (5.9.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.9/dist-packages (from dm-launchpad==0.5.0->dm-acme[jax]) (2.2.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.9/dist-packages (from dm-launchpad==0.5.0->dm-acme[jax]) (2.2.0)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.9/dist-packages (from dm-launchpad==0.5.0->dm-acme[jax]) (1.53.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8.0->dm-acme[jax]) (23.3.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8.0->dm-acme[jax]) (1.14.1)\n",
            "Collecting tensorboard<2.9,>=2.8\n",
            "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8.0->dm-acme[jax]) (3.8.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8.0->dm-acme[jax]) (3.3.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8.0->dm-acme[jax]) (0.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8.0->dm-acme[jax]) (1.6.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8.0->dm-acme[jax]) (16.0.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8.0->dm-acme[jax]) (0.2.0)\n",
            "Collecting keras-preprocessing>=1.1.1\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8.0->dm-acme[jax]) (1.16.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.5/462.5 KB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8.0->dm-acme[jax]) (0.32.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8.0->dm-acme[jax]) (67.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets==4.4.0->dm-acme[jax]) (4.65.0)\n",
            "Collecting dill\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets==4.4.0->dm-acme[jax]) (1.13.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets==4.4.0->dm-acme[jax]) (2.27.1)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets==4.4.0->dm-acme[jax]) (22.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets==4.4.0->dm-acme[jax]) (0.18.3)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets==4.4.0->dm-acme[jax]) (2.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from tensorflow_probability==0.15.0->dm-acme[jax]) (4.4.2)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.9/dist-packages (from chex->dm-acme[jax]) (0.12.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.9/dist-packages (from jax->dm-acme[jax]) (1.10.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.9/dist-packages (from jax->dm-acme[jax]) (0.0.4)\n",
            "Collecting jmp>=0.0.2\n",
            "  Downloading jmp-0.0.4-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.9/dist-packages (from dm-haiku->dm-acme[jax]) (0.8.10)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.9/dist-packages (from flax->dm-acme[jax]) (0.1.35)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.9/dist-packages (from flax->dm-acme[jax]) (1.0.5)\n",
            "Requirement already satisfied: orbax in /usr/local/lib/python3.9/dist-packages (from flax->dm-acme[jax]) (0.1.7)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.9/dist-packages (from flax->dm-acme[jax]) (6.0)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.9/dist-packages (from flax->dm-acme[jax]) (13.3.3)\n",
            "Collecting distrax>=0.0.2\n",
            "  Downloading distrax-0.1.3-py3-none-any.whl (317 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.0/318.0 KB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow==2.8.0->dm-acme[jax]) (0.40.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->tensorflow-datasets==4.4.0->dm-acme[jax]) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->tensorflow-datasets==4.4.0->dm-acme[jax]) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->tensorflow-datasets==4.4.0->dm-acme[jax]) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->tensorflow-datasets==4.4.0->dm-acme[jax]) (2.0.12)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.9/dist-packages (from rich>=11.1->flax->dm-acme[jax]) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from rich>=11.1->flax->dm-acme[jax]) (2.14.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0->dm-acme[jax]) (2.2.3)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m96.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0->dm-acme[jax]) (3.4.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0->dm-acme[jax]) (1.8.1)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0->dm-acme[jax]) (2.17.1)\n",
            "Requirement already satisfied: cached_property in /usr/local/lib/python3.9/dist-packages (from orbax->flax->dm-acme[jax]) (1.5.2)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.9/dist-packages (from orbax->flax->dm-acme[jax]) (1.5.6)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.9/dist-packages (from orbax->flax->dm-acme[jax]) (5.12.0)\n",
            "Requirement already satisfied: etils in /usr/local/lib/python3.9/dist-packages (from orbax->flax->dm-acme[jax]) (1.1.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-metadata->tensorflow-datasets==4.4.0->dm-acme[jax]) (1.59.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0->dm-acme[jax]) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0->dm-acme[jax]) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0->dm-acme[jax]) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0->dm-acme[jax]) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8.0->dm-acme[jax]) (6.1.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.9/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=11.1->flax->dm-acme[jax]) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8.0->dm-acme[jax]) (2.1.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib_resources->orbax->flax->dm-acme[jax]) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0->dm-acme[jax]) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0->dm-acme[jax]) (3.2.2)\n",
            "Building wheels for collected packages: dm-acme\n",
            "  Building wheel for dm-acme (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dm-acme: filename=dm_acme-0.4.0-py3-none-any.whl size=571230 sha256=a32255886bf6f4e8e6c13cc1a79df308d3e388d18743e20d02dbf3e2f2f76575\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/b4/30/d0bdfb4057d59a63e0a0ee34287a23049fe988971c45227ff7\n",
            "Successfully built dm-acme\n",
            "Installing collected packages: tf-estimator-nightly, tensorflow-estimator, keras, tensorflow_probability, tensorboard-data-server, mock, keras-preprocessing, jmp, dm-reverb, dm-env, dill, dm-launchpad, dm-haiku, tensorflow-datasets, google-auth-oauthlib, dm-acme, tensorboard, distrax, tensorflow, rlax\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: tensorflow_probability\n",
            "    Found existing installation: tensorflow-probability 0.19.0\n",
            "    Uninstalling tensorflow-probability-0.19.0:\n",
            "      Successfully uninstalled tensorflow-probability-0.19.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.0\n",
            "    Uninstalling tensorboard-data-server-0.7.0:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.0\n",
            "  Attempting uninstall: tensorflow-datasets\n",
            "    Found existing installation: tensorflow-datasets 4.8.3\n",
            "    Uninstalling tensorflow-datasets-4.8.3:\n",
            "      Successfully uninstalled tensorflow-datasets-4.8.3\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.0.0\n",
            "    Uninstalling google-auth-oauthlib-1.0.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.0.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.1\n",
            "    Uninstalling tensorboard-2.12.1:\n",
            "      Successfully uninstalled tensorboard-2.12.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "Successfully installed dill-0.3.6 distrax-0.1.3 dm-acme-0.4.0 dm-env-1.6 dm-haiku-0.0.9 dm-launchpad-0.5.0 dm-reverb-0.7.0 google-auth-oauthlib-0.4.6 jmp-0.0.4 keras-2.8.0 keras-preprocessing-1.1.2 mock-5.0.1 rlax-0.1.5 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorflow-2.8.0 tensorflow-datasets-4.4.0 tensorflow-estimator-2.8.0 tensorflow_probability-0.15.0 tf-estimator-nightly-2.8.0.dev2021122109\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dm-acme[tf] in /usr/local/lib/python3.9/dist-packages (0.4.0)\n",
            "Requirement already satisfied: dm-env in /usr/local/lib/python3.9/dist-packages (from dm-acme[tf]) (1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from dm-acme[tf]) (1.22.4)\n",
            "Requirement already satisfied: dm-launchpad==0.5.0 in /usr/local/lib/python3.9/dist-packages (from dm-acme[tf]) (0.5.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from dm-acme[tf]) (1.4.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.9/dist-packages (from dm-acme[tf]) (0.1.8)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from dm-acme[tf]) (8.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from dm-acme[tf]) (4.5.0)\n",
            "Collecting trfl\n",
            "  Downloading trfl-1.2.0-py3-none-any.whl (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 KB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras==2.8.0 in /usr/local/lib/python3.9/dist-packages (from dm-acme[tf]) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-datasets==4.4.0 in /usr/local/lib/python3.9/dist-packages (from dm-acme[tf]) (4.4.0)\n",
            "Requirement already satisfied: dm-reverb==0.7.0 in /usr/local/lib/python3.9/dist-packages (from dm-acme[tf]) (0.7.0)\n",
            "Requirement already satisfied: tensorflow-probability==0.15.0 in /usr/local/lib/python3.9/dist-packages (from dm-acme[tf]) (0.15.0)\n",
            "Collecting dm-sonnet\n",
            "  Downloading dm_sonnet-2.0.1-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.4/268.4 KB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow==2.8.0 in /usr/local/lib/python3.9/dist-packages (from dm-acme[tf]) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-estimator==2.8.0 in /usr/local/lib/python3.9/dist-packages (from dm-acme[tf]) (2.8.0)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.9/dist-packages (from dm-launchpad==0.5.0->dm-acme[tf]) (1.53.0)\n",
            "Requirement already satisfied: mock in /usr/local/lib/python3.9/dist-packages (from dm-launchpad==0.5.0->dm-acme[tf]) (5.0.1)\n",
            "Requirement already satisfied: portpicker in /usr/local/lib/python3.9/dist-packages (from dm-launchpad==0.5.0->dm-acme[tf]) (1.3.9)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from dm-launchpad==0.5.0->dm-acme[tf]) (5.9.4)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.9/dist-packages (from dm-launchpad==0.5.0->dm-acme[tf]) (2.2.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.9/dist-packages (from dm-launchpad==0.5.0->dm-acme[tf]) (2.2.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.9/dist-packages (from dm-launchpad==0.5.0->dm-acme[tf]) (3.20.3)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8.0->dm-acme[tf]) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8.0->dm-acme[tf]) (2.8.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8.0->dm-acme[tf]) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8.0->dm-acme[tf]) (1.14.1)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8.0->dm-acme[tf]) (23.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8.0->dm-acme[tf]) (67.6.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8.0->dm-acme[tf]) (1.16.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8.0->dm-acme[tf]) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8.0->dm-acme[tf]) (0.2.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8.0->dm-acme[tf]) (0.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8.0->dm-acme[tf]) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8.0->dm-acme[tf]) (0.32.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8.0->dm-acme[tf]) (3.8.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8.0->dm-acme[tf]) (16.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets==4.4.0->dm-acme[tf]) (4.65.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets==4.4.0->dm-acme[tf]) (2.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets==4.4.0->dm-acme[tf]) (0.18.3)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets==4.4.0->dm-acme[tf]) (0.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets==4.4.0->dm-acme[tf]) (2.27.1)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets==4.4.0->dm-acme[tf]) (22.2.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets==4.4.0->dm-acme[tf]) (1.13.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from tensorflow-probability==0.15.0->dm-acme[tf]) (4.4.2)\n",
            "Requirement already satisfied: tabulate>=0.7.5 in /usr/local/lib/python3.9/dist-packages (from dm-sonnet->dm-acme[tf]) (0.8.10)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow==2.8.0->dm-acme[tf]) (0.40.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->tensorflow-datasets==4.4.0->dm-acme[tf]) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->tensorflow-datasets==4.4.0->dm-acme[tf]) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->tensorflow-datasets==4.4.0->dm-acme[tf]) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->tensorflow-datasets==4.4.0->dm-acme[tf]) (3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0->dm-acme[tf]) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0->dm-acme[tf]) (2.2.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0->dm-acme[tf]) (2.17.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0->dm-acme[tf]) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0->dm-acme[tf]) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0->dm-acme[tf]) (3.4.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-metadata->tensorflow-datasets==4.4.0->dm-acme[tf]) (1.59.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0->dm-acme[tf]) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0->dm-acme[tf]) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0->dm-acme[tf]) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0->dm-acme[tf]) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8.0->dm-acme[tf]) (6.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8.0->dm-acme[tf]) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8.0->dm-acme[tf]) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0->dm-acme[tf]) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0->dm-acme[tf]) (3.2.2)\n",
            "Installing collected packages: trfl, dm-sonnet\n",
            "Successfully installed dm-sonnet-2.0.1 trfl-1.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dm-haiku in /usr/local/lib/python3.9/dist-packages (0.0.9)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.9/dist-packages (from dm-haiku) (1.22.4)\n",
            "Requirement already satisfied: jmp>=0.0.2 in /usr/local/lib/python3.9/dist-packages (from dm-haiku) (0.0.4)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.9/dist-packages (from dm-haiku) (1.4.0)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.9/dist-packages (from dm-haiku) (0.8.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: chex in /usr/local/lib/python3.9/dist-packages (0.1.7)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from chex) (4.5.0)\n",
            "Requirement already satisfied: jax>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from chex) (0.4.7)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.9/dist-packages (from chex) (0.1.8)\n",
            "Requirement already satisfied: absl-py>=0.9.0 in /usr/local/lib/python3.9/dist-packages (from chex) (1.4.0)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.9/dist-packages (from chex) (0.12.0)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.9/dist-packages (from chex) (0.4.7+cuda11.cudnn86)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.9/dist-packages (from chex) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.9/dist-packages (from jax>=0.4.6->chex) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.9/dist-packages (from jax>=0.4.6->chex) (1.10.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.9/dist-packages (from jax>=0.4.6->chex) (0.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.9/dist-packages (0.1.4)\n",
            "Requirement already satisfied: chex>=0.1.5 in /usr/local/lib/python3.9/dist-packages (from optax) (0.1.7)\n",
            "Requirement already satisfied: jax>=0.1.55 in /usr/local/lib/python3.9/dist-packages (from optax) (0.4.7)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.9/dist-packages (from optax) (1.22.4)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.9/dist-packages (from optax) (1.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.9/dist-packages (from optax) (4.5.0)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.9/dist-packages (from optax) (0.4.7+cuda11.cudnn86)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.9/dist-packages (from chex>=0.1.5->optax) (0.1.8)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.9/dist-packages (from chex>=0.1.5->optax) (0.12.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.9/dist-packages (from jax>=0.1.55->optax) (0.0.4)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.9/dist-packages (from jax>=0.1.55->optax) (1.10.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.9/dist-packages (from jax>=0.1.55->optax) (3.3.0)\n"
          ]
        }
      ],
      "source": [
        "#@title Installations  { form-width: \"30%\" }\n",
        "\n",
        "# This is just for the purpose of this colab. Please do not share a ssh\n",
        "# private key in real life, it is a really unsafe practice.\n",
        "GITHUB_PRIVATE_KEY = \"\"\"-----BEGIN OPENSSH PRIVATE KEY-----\n",
        "b3BlbnNzaC1rZXktdjEAAAAABG5vbmUAAAAEbm9uZQAAAAAAAAABAAAAMwAAAAtzc2gtZW\n",
        "QyNTUxOQAAACD5ow+qHLZLVosHfeGcGeJKQgwUlPYgoFliCEsshiFhXwAAALCn99V2p/fV\n",
        "dgAAAAtzc2gtZWQyNTUxOQAAACD5ow+qHLZLVosHfeGcGeJKQgwUlPYgoFliCEsshiFhXw\n",
        "AAAECJ+OOLQqiwINexx26mmQt6FL5xXYHRf9Jv2UzahlW0avmjD6octktWiwd94ZwZ4kpC\n",
        "DBSU9iCgWWIISyyGIWFfAAAAKm1yaXZpZXJlQG1yaXZpZXJlLW1hY2Jvb2twcm8ucm9hbS\n",
        "5pbnRlcm5hbAECAw==\n",
        "-----END OPENSSH PRIVATE KEY-----\n",
        "\"\"\"\n",
        "\n",
        "# Create the directory if it doesn't exist.\n",
        "! mkdir -p /root/.ssh\n",
        "# Write the key\n",
        "with open(\"/root/.ssh/id_ed25519\", \"w\") as f:\n",
        "  f.write(GITHUB_PRIVATE_KEY)\n",
        "# Add github.com to our known hosts\n",
        "! ssh-keyscan -t ed25519 github.com >> ~/.ssh/known_hosts\n",
        "# Restrict the key permissions, or else SSH will complain.\n",
        "! chmod go-rwx /root/.ssh/id_ed25519\n",
        "\n",
        "# Clone and install the RL Games repository\n",
        "! if [ -d \"rl_games\" ]; then echo \"rl_games directory exists.\"; else git clone git@github.com:Molugan/rl_games.git; fi\n",
        "! cd rl_games ; git pull;  pip install .\n",
        "\n",
        "# Other dependencies\n",
        "# If you just want to play your environment and does not intend to use either\n",
        "# jax or haiku you can comment this part.\n",
        "!pip install dm-acme[jax]\n",
        "!pip install dm-acme[tf]\n",
        "!pip install dm-haiku\n",
        "!pip install chex\n",
        "!pip install optax"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import math\n",
        "import time\n",
        "import numpy as np\n",
        "from gym import utils\n",
        "import enum\n",
        "from typing import *\n",
        "import chex\n",
        "#Importation Pour DQN\n",
        "import random\n",
        "import jax\n",
        "from jax import tree_util\n",
        "import optax\n",
        "import jax.numpy as jnp\n",
        "import haiku as hk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqzZquuU2xTK",
        "outputId": "78dfbbfd-80c0-47c1-ddca-e2c5cca555c2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/jax/_src/deprecations.py:51: DeprecationWarning: jax.numpy.DeviceArray is deprecated. Use jax.Array.\n",
            "  warnings.warn(message, DeprecationWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7qrEETnyOHL"
      },
      "source": [
        "## What you are expected to do:\n",
        "\n",
        "First off, constitute groups of 5 or less and fill in this [sheet](https://docs.google.com/spreadsheets/d/16TqSBGN33izSbom9-Vk2KYAxeYpEnz79-ylCHrTQiEA/edit#gid=0).\n",
        "You are then asked to:\n",
        "- Implement an agent to reach a score as high as you can on the environment within 2h of GPU compute. The code should be well designed and commented. You are not required to use reinforcement learning, but can if you find it useful. You can take inspiration from both the practicals and any online codebase that you may find useful, provided you reference it. However any suspicion of plagiarism on another team will results in grades being divided by two for both teams. The states of the environment are purposefully obfuscated, it is your job to find a representation that will be easily ingestible by whatever method you are going to be using. Two notes:\n",
        "  - Since GPU access is limited on Colab, you may want to experiment with CPUs and only use GPUs for your final run. Depending on the kind of algorithms you implement there is not necessarily going to be a huge difference.\n",
        "  - It is obviously forbidden to load external weights, that could be used to checkpoint your training.\n",
        "- Write a report (2-4 pages) explaining the approach you took in details, the hyperparameter searches you performed, and the final results you obtained.\n",
        "\n",
        "## Deadline\n",
        "You should complete this project and send us our results by April 7th 11:59pm, you will get a penalty of one point by day of delay.\n",
        "\n",
        "## Evaluation\n",
        "\n",
        "We are going to run your notebook on a Colab GPU instance for one hour and we will consider the performance of your model after that time.\n",
        "\n",
        "Grade decomposition:\n",
        "\n",
        "- Report 4pts:\n",
        "  - Method description.\n",
        "  - Hyperparameter choice explanation.\n",
        "  - Results presentation.\n",
        "- Code 4pts:\n",
        "  - Does the method described in the report match the method implemented?\n",
        "  - Is the code readable?\n",
        "  - Is the code well presented and documented?\n",
        "- Performance 5 pts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztgSWy0fYvY5"
      },
      "source": [
        "## The environment\n",
        "\n",
        "We will use the Flappy Bird environment defined in the deep_rl package. Let's have a closer look at it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CMk5FLsimhhx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c95ea33c-04e1-4f2b-bb86-509889d9491a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    Welcome to our custom flappy bird game !\n",
            "\n",
            "    A bird moves at a constant horizontal speed while gravity governs the vertical axis.\n",
            "    The goal is to make the bird avoid obstacles on the screen for as long as possible.\n",
            "\n",
            "    At each step. two actions are available:\n",
            "        0: do nothing and let it fall.\n",
            "        1: push the bird upward\n",
            "\n",
            "    Observations have the following shape:\n",
            "        BIRD_COORDINATES, [BAR_0, BAR_1, ..., BAR_N]\n",
            "\n",
            "    Where:\n",
            "        BIRD_COORDINATES = (X_BIRD, Y_BIRD, V_Y_BIRD)\n",
            "        WIth:\n",
            "            - X_BIRD: the position of the bird on the x-axis\n",
            "            - Y_BIRD: the position of the bird on the y-axis\n",
            "            - V_Y_BIRD: the velocity of the bird along the y-axis\n",
            "\n",
            "        BAR_0, BAR_1, ... , BAR_N are the coordinates of the bars visibles in the \n",
            "        environment.\n",
            "\n",
            "        With BAR_i = (X_LEFT, X_RIGHT, HEIGHT, POSITION)\n",
            "        Where BAR_i is a rectangle with:\n",
            "            X_LEFT: is the position of the left border of the bar\n",
            "            X_RIGHT: is the position of the right border of the bar\n",
            "            HEIGHT: is the bar's height\n",
            "            POISTION: (bool) is True if the bar is on top of the screen and False\n",
            "                elsewhere.\n",
            "\n",
            "        All (non-boolean) coordinates are floating points in [0, 1].\n",
            "\n",
            "        For example, if we have the following observation:\n",
            "\n",
            "            (0.5, 0.7, 0.), ((0.3, 0.4, 0.2, True), (0.1, 0.2, 0.4, False))\n",
            "\n",
            "        The bird is at coordinates (0.5, 0.7) with a null velocity. There are\n",
            "        two bars on the screen. The first bar is 'on top' so: its bottom left corner \n",
            "        is at position (0.3, 1 - 0.2) = (0.3, 0.8) and its top right corer is at\n",
            "        (0.4, 1.). The second bar is at the bottom, so: its bottom left corner\n",
            "        is at position (0.1, 0.) and its top right one it at (0.2, 0.4).\n",
            "\n",
            "        Note: the bars can be in any order.\n",
            "\n",
            "    Rewards:\n",
            "        the base reward at each step is 0\n",
            "        the agent gain one point each time the bird passes a bar successfully\n",
            "        the agent loses one point if the bird crashes (game over)\n",
            "\n",
            "    Minimal resolution recommended for rendering: 20 rows and 20 columns.\n",
            "\n",
            "    How to interact with the environment:\n",
            "        reset(): reset the environment\n",
            "        min_res: gives the minimal resolution (rows, cols) recomended for the environment\n",
            "        step(action : int): action must be 0 or 1. Update the environment with the given \n",
            "            action and returns next_obs, reward, done.\n",
            "            Where:\n",
            "                - obs is the next observation of the environment\n",
            "                - reward is the reward obtained\n",
            "                - done is wether or not the episode is over\n",
            "    \n"
          ]
        }
      ],
      "source": [
        "from deep_rl.environments.flappy_bird import FlappyBird\n",
        "\n",
        "env = FlappyBird(\n",
        "        gravity=0.05,\n",
        "        force_push=0.1,\n",
        "        vx=0.05,\n",
        "        prob_new_bar=1,\n",
        "        invictus_mode=False,\n",
        "        max_height_bar=0.5,\n",
        "    )\n",
        "\n",
        "print(env.help)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOFXHhUYmhVL"
      },
      "source": [
        "For example let's interact with it a little bit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOVy4waHAivf"
      },
      "source": [
        "To simplify typing a bit, the deep_rl package implements a new type `FlappyObs` which corresponds to a state of the flappy bird environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kwQsyfBBAxiA"
      },
      "outputs": [],
      "source": [
        "from typing import List, Tuple\n",
        "\n",
        "BarObs = Tuple[float, float, float, bool]\n",
        "BirdObs = Tuple[float, float, float]\n",
        "FlappyObs = Tuple[BirdObs, List[BarObs]]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title DEBUG A ENLEVER\n",
        "from deep_rl.project_values import PROJECT_FLAPPY_BIRD_ENV\n",
        "env = PROJECT_FLAPPY_BIRD_ENV\n",
        "\n",
        "def state_transform( state : FlappyObs ):\n",
        "\n",
        "    obstacles = state[1]\n",
        "\n",
        "    ground = []\n",
        "    sky = []\n",
        "    obstacles = sorted(obstacles, key=lambda x: x[0])\n",
        "    for obs in obstacles:\n",
        "        if obs[1] > 0.5:\n",
        "            if obs[3]:#Up\n",
        "                sky.append(obs)\n",
        "            else:\n",
        "                ground.append(obs)\n",
        "    \n",
        "    K = 1\n",
        "    vect = np.empty(2 + 2 * K * 3)\n",
        "    i = 2\n",
        "    for lst in [ground, sky]:\n",
        "        for k in range(K):\n",
        "            if k < len(lst):\n",
        "                obs = lst[k]\n",
        "                vect[i] = obs[0]    # x_min\n",
        "                vect[i+1] = obs[1]  # x_max\n",
        "                vect[i+2] = obs[2]  # height\n",
        "            else:\n",
        "                vect[i] = 1\n",
        "                vect[i+1] = 1.1\n",
        "                vect[i+2] = 0\n",
        "            i += 3\n",
        "\n",
        "    return vect\n",
        "  \n",
        "  # obstacle = state[1]\n",
        "  # if len(obstacle)==0:\n",
        "  #   return np.array([state[0][0], state[0][1], state[0][2], 0, 0, 0, 0, 0, 0, 0, 0])\n",
        "\n",
        "  # nearest_ground = [0,1,1,0]\n",
        "  # nearest_sky = [0,1,1,0]\n",
        "\n",
        "  # for obs in obstacle:\n",
        "  #   print(\"bonjour\")\n",
        "  #   if 0.5 <= obs[1]:#Obstacle  is Coming\n",
        "  #     if obs[3]:#Up\n",
        "  #       nearest_sky[0] += 1\n",
        "  #       if obs [0]< nearest_sky[1]:#Nearest   \n",
        "  #         nearest_sky[1] = obs[0]\n",
        "  #         nearest_sky[2] = obs[1]\n",
        "  #         nearest_sky[3] = 1 - obs[2]\n",
        "  #     else :#Down\n",
        "  #       nearest_ground[0] +=1\n",
        "  #       if obs[0] < nearest_ground[1]:\n",
        "  #         nearest_ground[1] = obs[0]\n",
        "  #         nearest_ground[2] = obs[1]\n",
        "  #         nearest_ground[3] = obs[2]\n",
        "\n",
        "  # return np.array([state[0][0], state[0][1], state[0][2], nearest_sky[0], nearest_sky[1], nearest_sky[2], nearest_sky[3], nearest_ground[0], nearest_ground[1], nearest_ground[2], nearest_ground[3]])"
      ],
      "metadata": {
        "id": "zgFRS2veP1ey"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(state_transform(((0.5, 0.2, 0.1), [(0.8499999999999999, 0.9499999999999998, 0.31578032374565199, False)])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhoZMrGbj553",
        "outputId": "7ee84d54-e2df-4397-8b70-117c2760935b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.48872486e-315 0.00000000e+000 8.50000000e-001 9.50000000e-001\n",
            " 3.15780324e-001 1.00000000e+000 1.10000000e+000 0.00000000e+000]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bUEklG8l726x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5583ada9-8261-4a20-f5ad-bb92c2d61ca8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We should use at least 20 rows and 20 when rendering the environment\n",
            "First observation when reseting the environment:\n",
            "((0.5, 0.5, 0.0), [])\n",
            "[0.5 0.5 0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
            "\n",
            "Now, let's perform a few steps\n",
            "\n",
            "Step 1: we let the bird fall\n",
            "Observation: ((0.5, 0.45, -0.05), [])\n",
            "Reward: 0\n",
            "Game over: False\n",
            "[ 0.5   0.45 -0.05  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
            "\n",
            "Step 2: we push the bird up\n",
            "Observation: ((0.5, 0.45, 0.0), [(1.0, 1.1, 0.07822769517733386, False)])\n",
            "Reward: 0\n",
            "Game over: False\n",
            "bonjour\n",
            "[0.5  0.45 0.   0.   1.   1.   0.   1.   1.   1.   0.  ]\n",
            "\n",
            "Step 3: we push the bird up again\n",
            "Observation: ((0.5, 0.5, 0.05), [(0.95, 1.05, 0.07822769517733386, False)])\n",
            "Reward: 0\n",
            "Game over: False\n",
            "bonjour\n",
            "[0.5       0.5       0.05      0.        1.        1.        0.\n",
            " 1.        0.95      1.05      0.0782277]\n",
            "\n",
            "Step 4: we push the bird up again\n",
            "Observation: ((0.5, 0.6, 0.1), [(0.8999999999999999, 0.9999999999999999, 0.07822769517733386, False)])\n",
            "Reward: 0\n",
            "Game over: False\n",
            "bonjour\n",
            "[0.5       0.6       0.1       0.        1.        1.        0.\n",
            " 1.        0.9       1.        0.0782277]\n",
            "\n",
            "Step 5: we push the bird up again\n",
            "Observation: ((0.5, 0.65, 0.05), [(0.8499999999999999, 0.9499999999999998, 0.07822769517733386, False)])\n",
            "Reward: 0\n",
            "Game over: False\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rows, cols = env.min_res\n",
        "print(f\"We should use at least {rows} rows and {cols} when rendering the environment\")\n",
        "\n",
        "N = 21\n",
        "\n",
        "obs_reset = env.reset()\n",
        "print(\"First observation when reseting the environment:\")\n",
        "print(obs_reset)\n",
        "print(state_transform(obs_reset))\n",
        "print()\n",
        "print(\"Now, let's perform a few steps\\n\")\n",
        "\n",
        "print(\"Step 1: we let the bird fall\")\n",
        "obs, reward, done = env.step(0)\n",
        "print(f\"Observation: {obs}\")\n",
        "print(f\"Reward: {reward}\")\n",
        "print(f\"Game over: {done}\")\n",
        "print(state_transform(obs))\n",
        "print()\n",
        "\n",
        "print(\"Step 2: we push the bird up\")\n",
        "obs, reward, done = env.step(1)\n",
        "print(f\"Observation: {obs}\")\n",
        "print(f\"Reward: {reward}\")\n",
        "print(f\"Game over: {done}\")\n",
        "print(state_transform(obs))\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Step 3: we push the bird up again\")\n",
        "obs, reward, done = env.step(1)\n",
        "print(f\"Observation: {obs}\")\n",
        "print(f\"Reward: {reward}\")\n",
        "print(f\"Game over: {done}\")\n",
        "print(state_transform(obs))\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Step 4: we push the bird up again\")\n",
        "obs, reward, done = env.step(1)\n",
        "print(f\"Observation: {obs}\")\n",
        "print(f\"Reward: {reward}\")\n",
        "print(f\"Game over: {done}\")\n",
        "\n",
        "print(state_transform(obs))\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Step 5: we push the bird up again\")\n",
        "obs, reward, done = env.step(0)\n",
        "print(f\"Observation: {obs}\")\n",
        "print(f\"Reward: {reward}\")\n",
        "print(f\"Game over: {done}\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UI7HQF1zhNcW"
      },
      "source": [
        "## Baseline\n",
        "\n",
        "We provide you with a simple baseline: the `StableAgent` which does nothing more than keeping the bird stable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-0xIH_5DB4f4"
      },
      "outputs": [],
      "source": [
        "from deep_rl.environments.flappy_bird import FlappyObs\n",
        "\n",
        "class StableAgent:\n",
        "  \"\"\"An agent which just keeps the bird stable.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               target_y : float = 0.5):\n",
        "    self._target_y = target_y\n",
        "\n",
        "  def sample_action(self,\n",
        "                    observation: FlappyObs,\n",
        "                    evaluation: bool,\n",
        "                    ) -> int:\n",
        "    _, y_bird, v_y_bird = observation[0]\n",
        "\n",
        "    if y_bird <= self._target_y and v_y_bird <= 0:\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnX6ij-gCCIN"
      },
      "source": [
        "Let's see how a single runs works in practice with this agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Q7EHsNT6CG0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05fd0eda-c4a4-456b-f36f-9e11969aed2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "　　　　　🟩🟩🟩🟩🟩🟩🟩　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　\n",
            "　　　　　🟩🟩🟩🟩🟩🟩🟩　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　\n",
            "　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　\n",
            "　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　\n",
            "　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　\n",
            "　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　\n",
            "　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　\n",
            "　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　\n",
            "　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　\n",
            "　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　\n",
            "　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　\n",
            "　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　\n",
            "　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　\n",
            "　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　\n",
            "　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　🐤　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　\n",
            "　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　\n",
            "　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　\n",
            "　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　\n",
            "　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　\n",
            "　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　\n",
            "　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　\n",
            "　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　\n",
            "　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　\n",
            "　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　\n",
            "　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　\n",
            "　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　\n",
            "　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　\n",
            "　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　\n",
            "　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　\n",
            "🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫\n",
            "TOTAL REWARD : 3\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from IPython.display import clear_output\n",
        "from deep_rl.terminal_renderer import BashRenderer\n",
        "from deep_rl.episode_runner import run_episode\n",
        "from deep_rl.project_values import PROJECT_FLAPPY_BIRD_ENV\n",
        "\n",
        "# We are going to render the environment !\n",
        "ROWS = 30\n",
        "COLS = 60\n",
        "# Because ipython sucks, I have not found a cleaner option to add\n",
        "# the refresher function\n",
        "renderer = BashRenderer(ROWS,\n",
        "                        COLS,\n",
        "                        clear_fn = lambda: clear_output(wait=True))\n",
        "\n",
        "# Flappy bird environment\n",
        "env = PROJECT_FLAPPY_BIRD_ENV\n",
        "\n",
        "# Our agent\n",
        "agent = StableAgent()\n",
        "\n",
        "# We run a single episode, with rendering, over a maximum of 100 steps\n",
        "run_episode(env,\n",
        "            agent,\n",
        "            max_steps=100,\n",
        "            renderer = renderer,\n",
        "            time_between_frame=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtqXMbKKDWYB"
      },
      "source": [
        "Without rendering now, let's see the average reward we can get over 100 episodes with this agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OUbF1hIHDcAN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a329ba13-39c5-46a1-ec12-594e0d85e26c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average reward over 100 episodes: 3.18\n"
          ]
        }
      ],
      "source": [
        "from deep_rl.project_values import PROJECT_FLAPPY_BIRD_ENV\n",
        "from deep_rl.episode_runner import run_episode\n",
        "\n",
        "# Flappy bird environment\n",
        "env = PROJECT_FLAPPY_BIRD_ENV\n",
        "\n",
        "# Our agent\n",
        "agent = StableAgent()\n",
        "\n",
        "N_EPISODES = 100\n",
        "\n",
        "reward = 0\n",
        "for _ in range(N_EPISODES):\n",
        "  reward+= run_episode(env, agent, max_steps=1000, renderer = None)\n",
        "\n",
        "reward /= N_EPISODES\n",
        "\n",
        "print(f\"Average reward over {N_EPISODES} episodes: {reward}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NX9TgKx_EirA"
      },
      "source": [
        "An now, you need to do much better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hyzsUZLnpHT"
      },
      "source": [
        "## Let's get to work !\n",
        "\n",
        "Design and train an agent that performs the best possible score on Flappy bird. You can use any method learned in this class. Here are the constraints:\n",
        "- if you chose a Deep learning algorithm, you must use jax and Haiku. Pytorch is not allowed for this project.\n",
        "- your agent should converge in less than an hour. To make sure of that, we will run your code and use whatever checkpoint you have dumped in the given time.\n",
        "- your agent must maximize the reward obtained over 100 episodes with a maximal number of 1000 steps per episode.\n",
        "\n",
        "Do not forget to write **clear and commented code**, you will also be evaluated on that.\n",
        "\n",
        "On top of that, you are asked to plot and analyse the relevant curves showing the evolution of your training loop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ5dLRk_0YeP"
      },
      "source": [
        "### Agent's API\n",
        "\n",
        "Your agent should implement a method, `sample_action`, which takes two arguments as input, the observed state and wether or not it is in evaluation mode, and pick the action to perform. Appart from that, you can add any other method you want to your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6BvoIFd6nrEr"
      },
      "outputs": [],
      "source": [
        "# class MyAgent:\n",
        "#   \"\"\"Your agent to beat Flappy bird.\"\"\"\n",
        "\n",
        "#   def __init__(self, ...):\n",
        "#   # Put whatever you want here\n",
        "\n",
        "#   def sample_action(self,\n",
        "#                     observation: FlappyObs,\n",
        "#                     evaluation: bool,\n",
        "#                     ) -> int:\n",
        "#     \"\"\"Pick the next action to perform\n",
        "\n",
        "#     Args:\n",
        "#       observation: state of the flappy bird environment.,\n",
        "#       evaluation: True if we are in evaluation mode, False if we are training.\n",
        "#     \"\"\"\n",
        "\n",
        "#     # Your code here !\n",
        "#     ...\n",
        "\n",
        "#     return action"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Replay BUFFER Uniform \n",
        "@chex.dataclass\n",
        "class Transition:\n",
        "  state_t: chex.Array\n",
        "  action_t: chex.Array\n",
        "  reward_t: chex.Array\n",
        "  done_t: chex.Array\n",
        "  state_tp1: chex.Array\n",
        "  memory_index: int\n",
        "\n",
        "\n",
        "class ReplayBuffer:\n",
        "  \"\"\"Fixed-size buffer to store transition tuples.\"\"\"\n",
        "\n",
        "  def __init__(self, buffer_capacity: int):\n",
        "      \"\"\"Initialize a ReplayBuffer object.\n",
        "      Args:\n",
        "         buffer_capacity: int: maximum transition store in the buffer\n",
        "      \"\"\"\n",
        "      self._memory = list()\n",
        "      self._memory_index = 0\n",
        "      self._maxlen = buffer_capacity\n",
        "\n",
        "  @property\n",
        "  def size(self) -> int:\n",
        "    # Return the current number of elements in the buffer.\n",
        "    return len(self._memory)\n",
        "\n",
        "  def add(self, state_t: chex.Array,\n",
        "          action_t: chex.Array,\n",
        "          reward_t: chex.Array,\n",
        "          done_t: chex.Array,\n",
        "          state_tp1: chex.Array) -> int:\n",
        "      \"\"\"Add a new transition to memory.\"\"\"\n",
        "      \n",
        "      \"\"\"\n",
        "      if not(done_t):\n",
        "        reward_t = 0.1  # TEST\n",
        "      else :\n",
        "        reward_t = -1\n",
        "      \"\"\" \n",
        "      new_transition = Transition(state_t=state_t, action_t=action_t, reward_t=reward_t, done_t=done_t, state_tp1=state_tp1, memory_index=self._memory_index)\n",
        "      if self.size < self._maxlen :\n",
        "        index = len(self._memory)\n",
        "        self._memory.append(new_transition)\n",
        "      else:\n",
        "        # self._memory.pop(0)\n",
        "        # self._memory.append(new_transition)\n",
        "        self._memory[self._memory_index] = new_transition\n",
        "        index = self._memory_index\n",
        "      \n",
        "      new_transition.memory_index = index\n",
        "\n",
        "      assert len(self._memory) <= self._maxlen\n",
        "      assert self._memory_index == index\n",
        "\n",
        "      self._memory_index = (self._memory_index + 1) % self._maxlen\n",
        "      return index\n",
        "\n",
        "  def sample(self) -> Transition:\n",
        "      \"\"\"Randomly sample a transition from memory.\"\"\"\n",
        "      assert self._memory, 'replay buffer is unfilled'\n",
        "      index = np.random.randint(self.size)\n",
        "      return self._memory[index]\n",
        "\n",
        "\n",
        "class PrioritizedReplayBuffer(ReplayBuffer):\n",
        "    def __init__(self, buffer_capacity: int, alpha: float = 0.7, beta: float = 0.5):\n",
        "        super().__init__(buffer_capacity)\n",
        "\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "\n",
        "        # Priority values are stored in a sum tree for efficiency\n",
        "        p = math.ceil(math.log(self._maxlen, 2))  # lowest 2^p >= N\n",
        "        self._index_offset = 2**p - 1\n",
        "        self._sum_tree = np.zeros(self._maxlen + self._index_offset)\n",
        "        self._max_priority = 1\n",
        "    \n",
        "    def add(self, *args, **kwargs):\n",
        "        index = super().add(*args, **kwargs)\n",
        "        self.set_priority(index, self._max_priority)\n",
        "\n",
        "    def set_priority(self, index, value):\n",
        "        i = self._index_offset + index\n",
        "        v = value ** self.alpha\n",
        "\n",
        "        update = v - self._sum_tree[i]\n",
        "        self._sum_tree[i] = v\n",
        "\n",
        "        while i:\n",
        "            i = (i-1) // 2\n",
        "            self._sum_tree[i] += update\n",
        "        \n",
        "        self._max_priority = max(self._max_priority, v)\n",
        "    \n",
        "    def sample(self) -> Transition:\n",
        "        \"\"\"Randomly sample a transition from memory.\"\"\"\n",
        "        assert self._memory, 'replay buffer is unfilled'\n",
        "        x = np.random.randint(self._sum_tree[0])\n",
        "        i = 0\n",
        "        while i < self._index_offset:\n",
        "            i = 2*i+1\n",
        "            if self._sum_tree[i] <= x:\n",
        "                x -= self._sum_tree[i]\n",
        "                i += 1\n",
        "        return self._memory[i - self._index_offset]\n",
        "\n",
        "\"\"\" test\n",
        "b = PrioritizedReplayBuffer(8)\n",
        "b._memory = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
        "print(b._sum_tree)\n",
        "b.set_priority(5, 3)\n",
        "print(b._sum_tree)\n",
        "b.set_priority(2, 5)\n",
        "print(b._sum_tree)\n",
        "b.set_priority(4, -1)\n",
        "print(b._sum_tree)\n",
        "b.set_priority(4, 2)\n",
        "print(b._sum_tree)\n",
        "\n",
        "print(\"\\nsamples:\", [b.sample() for i in range(15)])\n",
        "print(\"freqs:\", np.unique([b.sample() for i in range(1000)], return_counts=True)[1]/1000)\n",
        "print(\"expected:\", [0.5, 0.2, 0.3])\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class BatchedReplayBuffer(ReplayBuffer):\n",
        "\n",
        "  def sample_batch(self, batch_size) -> Transition:\n",
        "    \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
        "    assert len(self._memory) >= batch_size, 'Insuficient number of transitions in replay buffer'\n",
        "    # Your code here !\n",
        "    samples = [self.sample() for i in range(batch_size)]\n",
        "    kwargs = dict()\n",
        "    for attr in [\"state_t\", \"action_t\", \"reward_t\", \"done_t\", \"state_tp1\"]:\n",
        "        kwargs[attr] = np.array([getattr(s, attr) for s in samples])\n",
        "    return Transition(**kwargs, memory_index=None)\n",
        "\n",
        "\n",
        "class BatchedPrioritizedReplayBuffer(PrioritizedReplayBuffer):\n",
        "\n",
        "  def sample_batch(self, batch_size) -> Transition:\n",
        "    \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
        "    assert len(self._memory) >= batch_size, 'Insuficient number of transitions in replay buffer'\n",
        "    # Your code here !\n",
        "    samples = [self.sample() for i in range(batch_size)]\n",
        "    kwargs = dict()\n",
        "    for attr in [\"state_t\", \"action_t\", \"reward_t\", \"done_t\", \"state_tp1\", \"memory_index\"]:\n",
        "        kwargs[attr] = np.array([getattr(s, attr) for s in samples])\n",
        "    return Transition(**kwargs)\n"
      ],
      "metadata": {
        "id": "3aHDOx3d0u5E"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Agent Test\n",
        "\n",
        "# def Conv_network(x, env):\n",
        "#   x = x[..., None]\n",
        "#   x = jax.nn.relu( hk.Conv2D(output_channels = 32, kernel_shape = (6,6))(x) )\n",
        "#   x = jax.nn.relu( hk.Conv2D(output_channels = 64, kernel_shape = (3,3))(x) )\n",
        "#   x = hk.Flatten()(x)\n",
        "#   x = jax.nn.relu(hk.Linear(200)(x))\n",
        "#   x = hk.Linear(2)(x)\n",
        "#   return x\n",
        "\n",
        "def Conv_network(x, env):\n",
        "  hidden_dim = 50\n",
        "  layers = 3\n",
        "  activation = jax.nn.relu\n",
        "  \n",
        "\n",
        "  #x = hk.Flatten()(x)\n",
        "  for i in range(layers-1):\n",
        "    x = activation( hk.Linear(hidden_dim)(x))\n",
        "  out = hk.Linear(2)(x)  # last layer\n",
        "\n",
        "  return out\n",
        "\n",
        "\n",
        "@chex.dataclass\n",
        "class LearnerState:\n",
        "  online_params: hk.Params\n",
        "  target_params: hk.Params\n",
        "  opt_state: optax.OptState\n",
        "\n",
        "\n",
        "class DeepAgent:\n",
        "  def __init__(self,\n",
        "               env,\n",
        "               gamma,\n",
        "               eps,\n",
        "               learning_rate,\n",
        "               max_buffer_storage,\n",
        "               min_buffer_storage,\n",
        "               batch_size,\n",
        "               ema,\n",
        "               N,\n",
        "               use_prioritized_buffer=False,\n",
        "               seed = 0):\n",
        "    self.env = env\n",
        "    self.gamma = gamma\n",
        "    self.eps = eps\n",
        "    self.learning_rate = learning_rate\n",
        "    self.batch_size = batch_size\n",
        "    self.ema = ema\n",
        "    self.Na = 2\n",
        "    self.N = N\n",
        "\n",
        "    #Initialisation Replay Buffer\n",
        "    if use_prioritized_buffer:\n",
        "        self.buffer = BatchedPrioritizedReplayBuffer(max_buffer_storage)\n",
        "    else:\n",
        "      self.buffer = BatchedReplayBuffer(max_buffer_storage)\n",
        "\n",
        "    self.min_replay_buffer = min_buffer_storage\n",
        "\n",
        "    #Creation du reseau\n",
        "    self.init,self._apply = hk.without_apply_rng(hk.transform(self.deep_qfunction))\n",
        "    #les jit\n",
        "    self.apply = jax.jit(self._apply)\n",
        "    self.update = jax.jit(self.update_fn)\n",
        "\n",
        "    # Creation des clé des paramatres des reseaux\n",
        "    self.rng = jax.random.PRNGKey(seed)\n",
        "    self.rng, init_rng = jax.random.split(self.rng)\n",
        "    self.learner_state = self.init_state(init_rng)\n",
        "\n",
        "    #Etat actuel dans lequel on se trouve\n",
        "    self._state = self.first_observe(self.env.reset())\n",
        "\n",
        "  def state_transform(self, state : FlappyObs ):\n",
        "  \n",
        "    K = 2  # number of obstacles to keep\n",
        "\n",
        "    vect = np.empty(2 + 2 * K * 3)\n",
        "    vect[0] = state[0][1]  # bird_y\n",
        "    vect[1] = state[0][2]  # bird_vy\n",
        "\n",
        "    ground = []\n",
        "    sky = []\n",
        "    obstacles = sorted(state[1], key=lambda x: x[0])\n",
        "    for obs in obstacles:\n",
        "        if obs[1] > 0.5:\n",
        "            if obs[3]:#Up\n",
        "                sky.append(obs)\n",
        "            else:\n",
        "                ground.append(obs)\n",
        "    \n",
        "\n",
        "    i = 2\n",
        "    for lst in [ground, sky]:\n",
        "        for k in range(K):\n",
        "            if k < len(lst):\n",
        "                obs = lst[k]\n",
        "                vect[i] = obs[0]    # x_min\n",
        "                vect[i+1] = obs[1]  # x_max\n",
        "                vect[i+2] = obs[2]  # height\n",
        "            else:\n",
        "                vect[i] = 1\n",
        "                vect[i+1] = 1.1\n",
        "                vect[i+2] = 0\n",
        "            i += 3\n",
        "\n",
        "    return vect\n",
        "    \n",
        "    # bird = state[0]\n",
        "    # bars = state[1]\n",
        "    \n",
        "    # state_vect = np.zeros(20)  # 2 + 3 * 6\n",
        "\n",
        "    # # Add bird info\n",
        "    # state_vect[0] = bird[1]  # y coord\n",
        "    # state_vect[0] = bird[2]  # y velocity\n",
        "\n",
        "    # # Add info of the K first bars\n",
        "    # K = 3\n",
        "    # for i, bar in enumerate(bars[:3]):\n",
        "    #     state_vect[6*i+2] = bar[0] - bird[0]  # dist between bird and left border\n",
        "    #     state_vect[6*i+3] = bar[1] - bird[0]  # dist between bird and right border\n",
        "    #     state_vect[6*i+4] = (bar[2] - bird[1]) * bar[3]  # height from the ceiling (only if the bar comes from the ceiling, else 0)\n",
        "    #     state_vect[6*i+5] = (bar[2] - bird[1]) * (1 - bar[3])  # height from the ground (only if the bar comes from the ground, else 0)\n",
        "    #     state_vect[6*i+6] = bar[3]  # bool, whether if is on the ground or ceiling\n",
        "    #     state_vect[6*i+7] = 1  # it is a valid bar\n",
        "    \n",
        "    return state_vect\n",
        "\n",
        "  def deep_qfunction(self, state : FlappyObs):\n",
        "    return Conv_network(state, self.env)\n",
        "\n",
        "  def optimizer(self) -> optax.GradientTransformation:\n",
        "    return optax.adam(learning_rate=self.learning_rate)\n",
        "\n",
        "  def init_state(self, rng):\n",
        "    \"\"\"\n",
        "    Initialisation of the couple parameter for the network\n",
        "\n",
        "    Returns:\n",
        "      LeanerState Containing the online parameters, the target parameters and the optimal state of the optax optimisation\n",
        "    \"\"\"\n",
        "    state = self.state_transform([[0, 0, 0], []])\n",
        "    online_par = self.init(rng, state)\n",
        "    target_par = self.init(rng, state)\n",
        "    opt_st = self.optimizer().init(online_par)\n",
        "    return LearnerState(online_params = online_par, target_params = target_par,opt_state = opt_st)\n",
        "\n",
        "    \n",
        "  def sample_action(self, state: FlappyObs, eval:bool = False)-> int:\n",
        "    \"\"\"\n",
        "    From a given observation, choose an action\n",
        "\n",
        "    Args:\n",
        "      state : current observation of the environment\n",
        "      eval : if False we are in training setting, using epsilon greedy policy\n",
        "    Returns:\n",
        "      Action to pick\n",
        "    \"\"\"\n",
        "\n",
        "    U = np.random.uniform(0,1)\n",
        "    if U < self.eps and (not eval):\n",
        "      action = np.random.randint(self.Na)\n",
        "    else :\n",
        "      state_representation = self.state_transform(state)\n",
        "      state_value_action = self.apply(self.learner_state.online_params, state_representation)#[None] )\n",
        "      action = np.argmax(state_value_action)\n",
        "    \n",
        "    return action\n",
        "  \n",
        "  def first_observe(self, state : FlappyObs) -> None:\n",
        "    self._state = self.state_transform(state)\n",
        "  \n",
        "  #La fonction observe ainsi que les fonctions qu'elle appelle\n",
        "  def loss_fn(\n",
        "      self,\n",
        "      online_params: hk.Params,\n",
        "      target_params: hk.Params,\n",
        "      state_t: chex.Array,\n",
        "      action_t: chex.Array,\n",
        "      reward_t: chex.Array,\n",
        "      done_t: chex.Array,\n",
        "      state_tp1: chex.Array,\n",
        "      return_all_losses: bool = False,\n",
        "      ) -> chex.Array: \n",
        "      \"\"\"Computes the Q-learning loss\n",
        "\n",
        "      Args:\n",
        "        online_params: parameters of the online network\n",
        "        target_params: parameters of the target network\n",
        "        state_t: batch of observations at time t\n",
        "        action_t: batch of actions performed at time t\n",
        "        reward_t: batch of rewards obtained at time t\n",
        "        done_t: batch of end of episode status at time t\n",
        "        state_tp1: batch of states at time t+1\n",
        "        return_all_losses: whether to return the losses of every transition, or the average\n",
        "      Returns:\n",
        "        The Q-learning loss.\n",
        "      \"\"\"\n",
        "      Bootstrap = self.apply(target_params,state_tp1)\n",
        "      target = reward_t.reshape(-1,1) + self.gamma * jnp.max(Bootstrap, axis = 1,keepdims=True) * (1-done_t.reshape(-1,1))\n",
        "      Prediction = self.apply(online_params, state_t)\n",
        "      Prediction = jax.vmap(lambda x,y : x[y])(Prediction, action_t)\n",
        "      Prediction = Prediction.reshape(-1,1)\n",
        "      losses = (target - Prediction) ** 2\n",
        "      if return_all_losses:\n",
        "        return losses\n",
        "      return losses.mean()\n",
        "\n",
        "  def loss_DDQN_fn(\n",
        "      self,\n",
        "      online_params : hk.Params,\n",
        "      target_params : hk.Params,\n",
        "      state_t: chex.Array,\n",
        "      action_t:chex.Array,\n",
        "      reward_t: chex.Array,\n",
        "      done_t: chex.Array,\n",
        "      state_tp1 : chex.Array,\n",
        "      return_all_losses: bool = False,\n",
        "      ) -> chex.Array:\n",
        "      \"\"\"Computes the DDQN loss for mitigate the overestimation in the Q-learning loss\n",
        "  \n",
        "      Args:\n",
        "        online_params: parameters of the online network\n",
        "        target_params: parameters of the target network\n",
        "        state_t: batch of observations at time t\n",
        "        action_t: batch of actions performed at time t\n",
        "        reward_t: batch of rewards obtained at time t\n",
        "        done_t: batch of end of episode status at time t\n",
        "        state_tp1: batch of states at time t+1\n",
        "        return_all_losses: whether to return the losses of every transition, or the average\n",
        "      Returns:\n",
        "        The Double-Q-learning loss.\n",
        "      \"\"\"\n",
        "      Action = jnp.argmax(self.apply(online_params,state_tp1), axis = 1)\n",
        "      Bootstrap = self.apply(target_params,state_tp1)\n",
        "\n",
        "      Bootstrap = jax.vmap(lambda x,y : x[y])(Bootstrap, Action)\n",
        "\n",
        "     \n",
        "      target = reward_t.reshape(-1,1) + self.gamma * Bootstrap.reshape(-1,1) * (1-done_t.reshape(-1,1))\n",
        "      \n",
        "      \n",
        "      Prediction = self.apply(online_params, state_t)\n",
        "      Prediction = jax.vmap(lambda x,y : x[y])(Prediction, action_t)\n",
        "      Prediction = Prediction.reshape(-1,1)\n",
        "      losses = (target - Prediction) ** 2\n",
        "      if return_all_losses:\n",
        "        return losses\n",
        "      return losses.mean()\n",
        "\n",
        "\n",
        "  \n",
        "  \n",
        "  def update_fn(self,\n",
        "                 state: LearnerState,\n",
        "                 batch: Transition,\n",
        "                 ) -> Tuple[chex.Array, LearnerState]:\n",
        "    \"\"\"Get the next learner state given the current batch of transitions.\n",
        "\n",
        "    Args:\n",
        "      state: learner state before update.\n",
        "      batch: batch of experiences (st, at, rt, done_t, stp1)\n",
        "    Returns:\n",
        "      loss, learner state after update\n",
        "    \"\"\"\n",
        "\n",
        "    #Recuperation des variables\n",
        "    online_params = state.online_params\n",
        "    target_params = state.target_params\n",
        "    state_t =  batch.state_t\n",
        "    action_t =  batch.action_t\n",
        "    reward_t = batch.reward_t\n",
        "    done_t = batch.done_t\n",
        "    state_tp1 = batch.state_tp1\n",
        "    ema = self.ema\n",
        "\n",
        "    loss_fn = self.loss_fn\n",
        "    # loss_fn= self.loss_DDQN_fn\n",
        "    \n",
        "    # Compute gradients\n",
        "    loss_grad = jax.grad(loss_fn)\n",
        "    grad = loss_grad(online_params, target_params, state_t, action_t, reward_t, done_t, state_tp1)\n",
        "    # Apply gradients\n",
        "    updates, new_optstate = self.optimizer().update(grad, state.opt_state)\n",
        "    new_online_params = optax.apply_updates( online_params, updates)\n",
        "    \n",
        "    \n",
        "    # Update target network params as:\n",
        "    # target_params <- ema * target_params + (1 - ema) * new_online_params\n",
        "    target_params = jax.tree_map(lambda x,y : ema * x + (1-ema) * y, target_params,new_online_params) \n",
        "    next_state = LearnerState(online_params = new_online_params, target_params = target_params, opt_state = new_optstate)\n",
        "\n",
        "    losses = loss_fn(new_online_params, target_params, state_t, action_t, reward_t, done_t, state_tp1, return_all_losses=True)\n",
        "    return losses, next_state\n",
        "\n",
        "  \n",
        "  def observe(self,\n",
        "              action_t: chex.Array,\n",
        "              reward_t: chex.Array,\n",
        "              done_t: chex.Array,\n",
        "              state_tp1: FlappyObs,\n",
        "              ) -> chex.Array:\n",
        "    \"\"\"Updates the agent from the given observations.\n",
        "\n",
        "    Args:\n",
        "      action_t: action performed at time t.\n",
        "      reward_t: reward obtained after having performed action_t.\n",
        "      done_t: whether or not the episode is over after performing action_t.\n",
        "      state_tp1: state at which the environment is at time t+1.\n",
        "    Returns:\n",
        "      DQN loss obtained when updating the online network.\n",
        "    \"\"\"\n",
        "    state_tp1_representation = self.state_transform(state_tp1)\n",
        "    self.buffer.add(self._state, action_t, reward_t, done_t, state_tp1_representation)\n",
        "    self._state = state_tp1_representation\n",
        "\n",
        "    if self.buffer.size >= self.min_replay_buffer:\n",
        "      batch = self.buffer.sample_batch(self.batch_size)\n",
        "      losses, self.learner_state = self.update(self.learner_state, batch)\n",
        "\n",
        "      # Update priorities (if prioritized replay buffer)\n",
        "      if isinstance(self.buffer, BatchedPrioritizedReplayBuffer):\n",
        "        for sample_index, sample_loss in zip(batch.memory_index, losses):\n",
        "            priority = np.sqrt(sample_loss)\n",
        "            self.buffer.set_priority(sample_index, priority)\n",
        "\n",
        "      return losses.mean()\n",
        "    return 0.\n",
        "  "
      ],
      "metadata": {
        "id": "TbnBUzl62VJ8"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gHfxq9_E-zT"
      },
      "source": [
        "## Environment\n",
        "\n",
        "You must use the following flappy bird environment from the deep_rl package.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "XEt5Y82yPw0q"
      },
      "outputs": [],
      "source": [
        "from deep_rl.project_values import PROJECT_FLAPPY_BIRD_ENV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnY-RTgwELdS"
      },
      "source": [
        "### Training loop\n",
        "\n",
        "You can use the following training loop to train your agent. Do not hesitate to play with the different parameters or even modify the code if you think you have a better option."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "qdoO0UY92s2o"
      },
      "outputs": [],
      "source": [
        "from typing import List, Tuple\n",
        "from dataclasses import dataclass\n",
        "import time\n",
        "\n",
        "# Your training loop should perform in less than 2h.\n",
        "MAX_TIME_TRAINING = 3600 * 2\n",
        "\n",
        "@dataclass\n",
        "class EpisodeTrainingStatus:\n",
        "  episode_number: int\n",
        "  reward: float\n",
        "  training_time: float\n",
        "\n",
        "def run_episode_no_rendering(env,\n",
        "                             agent,\n",
        "                             evaluation: bool,\n",
        "                             max_steps: int,\n",
        "                             ) -> float:\n",
        "  \"\"\"Runs a single episode.\n",
        "\n",
        "  Args:\n",
        "    env: environment to consider.\n",
        "    agent: agent to run.\n",
        "    evaluation: if False, will train the agent.\n",
        "    max_steps: number of steps after wich the evaluation should be stoppped\n",
        "      no matter what.\n",
        "  Returns:\n",
        "    The total reward accumulated over the episode.\n",
        "\t\"\"\"\n",
        "  observation = env.reset()\n",
        "  agent.first_observe(observation)\n",
        "  tot_reward = 0\n",
        "\n",
        "  for step in range(max_steps):\n",
        "    action = agent.sample_action(observation, evaluation)\n",
        "    observation, reward, end_game = env.step(action)\n",
        "    tot_reward += reward\n",
        "    \n",
        "    if not evaluation:\n",
        "      agent.observe(action, reward, end_game, observation)\n",
        "\n",
        "    if end_game:\n",
        "      break\n",
        "\n",
        "  return tot_reward, step\n",
        "\n",
        "def train_agent(env,\n",
        "                agent,\n",
        "                num_episodes: int,\n",
        "                num_eval_episodes: int,\n",
        "                eval_every_N: int,\n",
        "                max_steps_episode: int,\n",
        "                max_time_training: float = MAX_TIME_TRAINING,\n",
        "                ) -> List[EpisodeTrainingStatus]:\n",
        "  \"\"\"Train your agent on the given environment.\n",
        "\n",
        "  Args:\n",
        "    env: environment to consider.\n",
        "    agent: agent to train.\n",
        "    num_episodes: number of episode to run for training.\n",
        "    eval_every_N: frequency at which the agent is evaluated.\n",
        "    max_steps_episode: maximal number of step per episode.\n",
        "    max_time_training: maximal duration of the training loop (in seconds).\n",
        "  Returns:\n",
        "    The total reward accumulated over the episode.\n",
        "\t\"\"\"\n",
        "\n",
        "  all_status = []\n",
        "  print(f\"Episode number  | Average reward  |  Steps (max={max_steps_episode})  | Time (s)\")\n",
        "  print(\"-------------------------------------------------------------------\")\n",
        "\n",
        "  start_time = time.time()\n",
        "\n",
        "  cur_time = start_time\n",
        "  for episode in range(num_episodes):\n",
        "\n",
        "    run_episode_no_rendering(env,\n",
        "                            agent,\n",
        "                            evaluation=False,\n",
        "                            max_steps=max_steps_episode)\n",
        "\n",
        "    if episode % eval_every_N == 0:\n",
        "      reward=0\n",
        "      steps = 0\n",
        "      d_time = time.time() - start_time\n",
        "      for _ in range(num_eval_episodes):\n",
        "        r, s = run_episode_no_rendering(env,\n",
        "                                        agent,\n",
        "                                        evaluation=True,\n",
        "                                        max_steps=max_steps_episode)\n",
        "        reward += r\n",
        "        steps += s\n",
        "      reward /= num_eval_episodes\n",
        "      steps /= num_eval_episodes\n",
        "\n",
        "      print(f\"\\t{episode}\\t|\\t{reward:7.2f}\\t\\t{steps:6.1f} \\t\\t{time.time() - cur_time:5.1f}\")\n",
        "      cur_time = time.time()\n",
        "\n",
        "      all_status.append(EpisodeTrainingStatus(episode_number=episode,\n",
        "                                              reward=reward,\n",
        "                                              training_time=d_time))\n",
        "\n",
        "      if d_time > max_time_training:\n",
        "        break\n",
        "\n",
        "  return all_status"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@ Uses of the training loop\n",
        "num_episodes = 10000\n",
        "num_eval_episodes = 100\n",
        "eval_every_N = 200\n",
        "\n",
        "env = PROJECT_FLAPPY_BIRD_ENV\n",
        "\n",
        "agent = DeepAgent(\n",
        "    env=PROJECT_FLAPPY_BIRD_ENV,\n",
        "    gamma=.99,\n",
        "    eps=.3,\n",
        "    learning_rate=3e-4,\n",
        "    max_buffer_storage=50000,\n",
        "    min_buffer_storage=32,\n",
        "    batch_size=32,\n",
        "    ema=0.7,\n",
        "    N = 21,\n",
        "    use_prioritized_buffer=False,\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "fREwwChjcN25"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L=train_agent(PROJECT_FLAPPY_BIRD_ENV,agent,num_episodes, num_eval_episodes, eval_every_N, 1000)"
      ],
      "metadata": {
        "id": "bp4Bb_9aN04-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdbced5d-6b4e-49c4-b8d7-119c6839ff15"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode number  | Average reward  |  Steps (max=1000)  | Time (s)\n",
            "-------------------------------------------------------------------\n",
            "\t0\t|\t  -1.00\t\t   3.8 \t\t  0.3\n",
            "\t200\t|\t   0.46\t\t  18.9 \t\t  8.0\n",
            "\t400\t|\t  30.09\t\t 154.3 \t\t 18.3\n",
            "\t600\t|\t  29.92\t\t 153.3 \t\t 22.4\n",
            "\t800\t|\t  44.31\t\t 215.3 \t\t 23.9\n",
            "\t1000\t|\t  59.39\t\t 281.9 \t\t 31.3\n",
            "\t1200\t|\t  53.79\t\t 256.5 \t\t 27.7\n",
            "\t1400\t|\t  50.90\t\t 244.7 \t\t 29.3\n",
            "\t1600\t|\t  77.78\t\t 363.6 \t\t 35.8\n",
            "\t1800\t|\t  67.28\t\t 315.8 \t\t 33.5\n",
            "\t2000\t|\t  86.23\t\t 401.2 \t\t 38.2\n",
            "\t2200\t|\t  82.14\t\t 377.8 \t\t 37.1\n",
            "\t2400\t|\t  94.42\t\t 428.3 \t\t 38.5\n",
            "\t2600\t|\t  78.15\t\t 363.4 \t\t 35.8\n",
            "\t2800\t|\t  93.85\t\t 435.4 \t\t 39.4\n",
            "\t3000\t|\t  85.88\t\t 398.1 \t\t 37.5\n",
            "\t3200\t|\t 103.74\t\t 478.3 \t\t 42.8\n",
            "\t3400\t|\t 103.76\t\t 472.1 \t\t 41.1\n",
            "\t3600\t|\t 106.87\t\t 489.6 \t\t 40.8\n",
            "\t3800\t|\t  99.58\t\t 455.8 \t\t 39.4\n",
            "\t4000\t|\t  99.10\t\t 459.2 \t\t 39.0\n",
            "\t4200\t|\t 101.03\t\t 461.3 \t\t 42.4\n",
            "\t4400\t|\t  95.12\t\t 437.6 \t\t 39.3\n",
            "\t4600\t|\t  99.05\t\t 454.8 \t\t 38.3\n",
            "\t4800\t|\t  98.03\t\t 452.4 \t\t 40.0\n",
            "\t5000\t|\t  90.49\t\t 417.9 \t\t 38.0\n",
            "\t5200\t|\t 104.27\t\t 475.2 \t\t 42.2\n",
            "\t5400\t|\t 116.20\t\t 530.9 \t\t 42.8\n",
            "\t5600\t|\t  98.95\t\t 454.8 \t\t 39.2\n",
            "\t5800\t|\t 105.73\t\t 485.0 \t\t 40.0\n",
            "\t6000\t|\t  94.68\t\t 434.7 \t\t 36.4\n",
            "\t6200\t|\t 100.53\t\t 460.8 \t\t 38.5\n",
            "\t6400\t|\t  92.49\t\t 426.8 \t\t 37.7\n",
            "\t6600\t|\t 108.02\t\t 495.3 \t\t 41.4\n",
            "\t6800\t|\t 121.68\t\t 552.2 \t\t 42.7\n",
            "\t7000\t|\t 114.84\t\t 524.1 \t\t 40.4\n",
            "\t7200\t|\t  92.32\t\t 424.6 \t\t 37.1\n",
            "\t7400\t|\t  80.66\t\t 373.6 \t\t 34.5\n",
            "\t7600\t|\t  78.55\t\t 361.2 \t\t 33.4\n",
            "\t7800\t|\t 119.33\t\t 543.4 \t\t 41.8\n",
            "\t8000\t|\t 100.17\t\t 459.9 \t\t 39.8\n",
            "\t8200\t|\t 123.29\t\t 564.3 \t\t 45.6\n",
            "\t8400\t|\t  86.86\t\t 399.6 \t\t 35.3\n",
            "\t8600\t|\t 132.87\t\t 606.6 \t\t 46.7\n",
            "\t8800\t|\t 125.59\t\t 572.3 \t\t 45.8\n",
            "\t9000\t|\t 104.19\t\t 481.4 \t\t 39.5\n",
            "\t9200\t|\t 110.92\t\t 505.2 \t\t 51.0\n",
            "\t9400\t|\t 108.94\t\t 497.7 \t\t 40.2\n",
            "\t9600\t|\t 118.72\t\t 542.3 \t\t 45.6\n",
            "\t9800\t|\t 113.25\t\t 516.1 \t\t 42.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.xlabel('Number of training episodes')\n",
        "plt.ylabel('Average return')\n",
        "episodes = []\n",
        "all_rewards = []\n",
        "for i in range(len(L)):\n",
        "  episodes.append(L[i].episode_number)\n",
        "  all_rewards.append(L[i].reward)\n",
        "plt.plot(episodes, all_rewards)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "odOT4pvGqYrS",
        "outputId": "758585e6-f15b-4f75-aefb-90b1c8187845"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f087113c760>]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sp6QTqEPENaW"
      },
      "source": [
        "### Visualisation\n",
        "\n",
        "You can use the following code to visualize a single run made by your agent. This can help you for debugging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "rBLse6KIEPZT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce3ba572-de42-45fe-ddbf-b4fa9745c41b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　🟩🟩🟩🟩🟩🟩🟩\n",
            "🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　🟩🟩🟩🟩🟩🟩🟩\n",
            "🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　🟩🟩🟩🟩🟩🟩🟩\n",
            "🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　🟩🟩🟩🟩🟩🟩🟩\n",
            "🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　🟩🟩🟩🟩🟩🟩🟩\n",
            "🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　🟩🟩🟩🟩🟩🟩🟩\n",
            "🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　🟩🟩🟩🟩🟩🟩🟩\n",
            "🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　🟩🟩🟩🟩🟩🟩🟩\n",
            "🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩\n",
            "🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩\n",
            "　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩\n",
            "　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩\n",
            "　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩\n",
            "　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　🐤　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩\n",
            "　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　\n",
            "　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　\n",
            "　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　\n",
            "　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　\n",
            "　　　　　　　　　　　　　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　\n",
            "　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　\n",
            "　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　\n",
            "　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　\n",
            "　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　\n",
            "　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　\n",
            "　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　\n",
            "　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　\n",
            "　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　\n",
            "　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　\n",
            "　　　　　　　　　　　　　　🟩🟩🟩🟩🟩🟩🟩　　　　　🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩　　　　　　　　　　　　　　　　　　　　　\n",
            "🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫🟫\n",
            "TOTAL REWARD : 65\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "from IPython.display import clear_output\n",
        "from deep_rl.project_values import PROJECT_FLAPPY_BIRD_ENV\n",
        "from deep_rl.terminal_renderer import BashRenderer\n",
        "from deep_rl.episode_runner import run_episode\n",
        "\n",
        "# Your agent\n",
        "#agent = ...\n",
        "\n",
        "# We are going to render the environment !\n",
        "ROWS = 30\n",
        "COLS = 60\n",
        "renderer = BashRenderer(ROWS,\n",
        "                        COLS,\n",
        "                        clear_fn= lambda: clear_output(wait=True))\n",
        "\n",
        "\n",
        "# We run a single episode, with rendering, over a maximum of 1000 steps\n",
        "run_episode(PROJECT_FLAPPY_BIRD_ENV,\n",
        "            agent,\n",
        "            max_steps= 1000,\n",
        "            evaluation = True,\n",
        "            renderer= renderer,\n",
        "            time_between_frame= 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "N_EPISODES = 100\n",
        "\n",
        "reward = 0\n",
        "for _ in range(N_EPISODES):\n",
        "  reward+= run_episode_no_rendering(env, agent, max_steps=1000, evaluation = True)\n",
        "\n",
        "reward /= N_EPISODES\n",
        "\n",
        "print(f\"Average reward over {N_EPISODES} episodes: {reward}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIcbQuwYxMhJ",
        "outputId": "7d3a860e-36e1-4909-c7ec-e6b204b8fcb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average reward over 100 episodes: 109.28\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}